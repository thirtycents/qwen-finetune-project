# ============================================================
# qwen3_lora_sft.yaml - Qwen3-0.6B LoRA SFT 训练配置
# ============================================================
# 这是 LLaMA-Factory 的训练配置文件。
# LLaMA-Factory 读取这个 YAML 文件来决定：
#   - 用哪个模型
#   - 怎么训练（LoRA、全参数等）
#   - 用什么数据
#   - 训练多久、学习率多少等超参数
#
# 使用方式：
#   llamafactory-cli train configs/qwen3_lora_sft.yaml
#
# 本配置针对 12GB 显存 GPU（如 RTX 4070）优化。
# ============================================================

# ============================================================
# 第一部分：模型配置
# ============================================================

# 模型名称或路径
# 这里使用 HuggingFace 上的模型标识符，首次运行会自动下载
# Qwen3-0.6B 是通义千问团队发布的 6 亿参数小模型
# 为什么选 0.6B？因为它足够小，单卡就能训练，适合学习和实验
model_name_or_path: Qwen/Qwen3-0.6B

# 对话模板
# 不同模型有不同的对话格式（特殊 token、角色标记等）
# qwen3 模板会自动添加 Qwen3 需要的 <|im_start|> 等特殊标记
# 如果模板选错，模型训练效果会很差，因为它无法理解对话结构
template: qwen3

# ============================================================
# 第二部分：训练方式配置
# ============================================================

# 训练阶段：sft = Supervised Fine-Tuning（监督微调）
# 原理：用标注好的数据（输入→正确输出）来教模型
# 其他选项：pt（预训练）、rm（奖励模型）、ppo（强化学习）、dpo（偏好对齐）
stage: sft

# 是否执行训练（设为 true 表示训练，false 可用于仅评估）
do_train: true

# 微调方式：lora = Low-Rank Adaptation（低秩适应）
# 原理：不修改原始模型的全部参数，而是在每一层旁边加一个"小旁路"
# 这个旁路由两个小矩阵（A 和 B）组成，参数量远小于原始层
# 优势：显存占用极低（只需存储 LoRA 参数），训练速度快
# 缺点：理论上效果略逊于全参数微调，但实际差距很小
finetuning_type: lora

# LoRA 应用到哪些层
# "all" 表示对模型所有线性层都加 LoRA 旁路
# 也可以指定具体层名如 "q_proj,v_proj"（只对注意力的 Q 和 V 矩阵加 LoRA）
# 为什么选 all？研究表明对所有层加 LoRA 效果最好，虽然参数稍多但仍远少于全参数
lora_target: all

# LoRA 秩（rank）
# 秩决定了"小旁路"矩阵的大小，秩越大，LoRA 能学到的东西越多，但参数也越多
# 常用值：8、16、32、64
# 32 是一个平衡点：对于 0.6B 模型，32 已经提供了足够的表达能力
# 太小（如 4）可能学不够，太大（如 128）浪费显存且容易过拟合
lora_rank: 32

# LoRA alpha（缩放因子）
# 公式：实际学习强度 = alpha / rank × LoRA输出
# alpha=64, rank=32 → 缩放系数=2.0
# 经验法则：alpha 通常设为 rank 的 2 倍，这样缩放系数为 2，训练较稳定
# 如果缩放太大，训练不稳定；太小，LoRA 的影响太弱
lora_alpha: 64

# LoRA dropout（随机丢弃率）
# 训练时随机"关闭"一部分 LoRA 参数，防止过拟合
# 0.05 表示 5% 的概率丢弃，是比较保守的值
# 数据量大时可以设 0（不丢弃），数据量小时可以设更高（如 0.1）
lora_dropout: 0.05

# ============================================================
# 第三部分：数据配置
# ============================================================

# 数据集名称（对应 dataset_info.json 中注册的名字）
dataset: xlam_fc_train

# 数据集配置文件目录（dataset_info.json 所在目录）
dataset_dir: ./configs

# 验证集名称（训练过程中定期用验证集评估模型效果）
eval_dataset: xlam_fc_val

# 最大序列长度（token 数）
# 超过这个长度的样本会被截断
# 2048 对函数调用任务足够了（大多数工具调用不会很长）
# 设太大会占用更多显存，设太小会丢失信息
cutoff_len: 2048

# ============================================================
# 第四部分：训练超参数
# ============================================================

# 每个 GPU 每次处理的样本数
# 2 是在 12GB 显存下比较安全的值
# batch_size 越大，训练越稳定但占用显存越多
# 如果显存溢出（OOM），可以改为 1
per_device_train_batch_size: 2

# 梯度累积步数
# 实际的有效 batch_size = per_device_batch_size × gradient_accumulation_steps
# 2 × 8 = 16，相当于每 16 个样本更新一次模型参数
# 为什么不直接设 batch_size=16？因为 12GB 显存不够！
# 梯度累积让我们用小显存模拟大 batch 的效果
gradient_accumulation_steps: 8

# 训练轮数
# 1 轮（epoch）= 遍历整个训练集一次
# 3 轮是常用值：太少学不够，太多容易过拟合（死记硬背训练数据）
# 对于 60k 数据量，3 轮通常足够模型学会函数调用格式
num_train_epochs: 3

# 学习率
# 控制每次参数更新的"步幅"大小
# 2e-4 = 0.0002，是 LoRA SFT 的常用值
# 太大→训练不稳定，loss 震荡甚至爆炸
# 太小→学习太慢，需要更多轮次才能收敛
# LoRA 的学习率通常比全参数微调（~1e-5）大，因为 LoRA 参数少，需要更大步幅
learning_rate: 2.0e-4

# 学习率调度器
# cosine（余弦退火）：学习率先保持较高，然后像余弦曲线一样平滑下降
# 原理：训练初期用大学习率快速学习，后期用小学习率精细调整
# 这比恒定学习率效果好，因为后期不需要大幅度更新了
lr_scheduler_type: cosine

# 预热比例
# 训练开始时，学习率从 0 逐渐增加到设定值
# 0.1 表示前 10% 的步数用于预热
# 为什么要预热？模型刚开始训练时状态不稳定，
# 直接用大学习率可能导致梯度爆炸，所以先"热身"
warmup_ratio: 0.1

# 每隔多少步打印一次训练日志（loss 值等）
# 10 步打印一次，方便观察训练是否正常
logging_steps: 10

# 每隔多少步保存一次模型检查点
# 500 步保存一次，防止训练中断导致进度全丢
save_steps: 500

# 每隔多少步在验证集上评估一次
# 和 save_steps 保持一致，每次保存时也评估
eval_steps: 500

# 评估策略
# steps 表示按步数评估（而非按轮次 epoch）
eval_strategy: steps

# 最多保留多少个检查点
# 3 表示只保留最新的 3 个，旧的自动删除
# 每个检查点可能占几百 MB，限制数量节省磁盘
save_total_limit: 3

# ============================================================
# 第五部分：输出与硬件配置
# ============================================================

# 训练输出目录（模型检查点、日志等保存在这里）
output_dir: ./outputs/qwen3-0.6b-fc-lora

# 使用 bf16（bfloat16）半精度训练
# bf16 用 16 位浮点数代替 32 位，显存占用减半，训练速度更快
# bf16 比 fp16 更稳定（数值范围更大，不容易溢出）
# 现代 NVIDIA GPU（Ampere/Ada/Blackwell 架构）原生支持 bf16
bf16: true

# 日志报告工具
# none 表示不使用 wandb 等在线日志工具
# 如果你想用 wandb 可视化训练曲线，改为 "wandb" 并登录
report_to: none  # 改为 "wandb" 可启用 Weights & Biases 训练可视化

# 覆盖已有的输出目录
# 如果 output_dir 已存在，直接覆盖（不会报错）
overwrite_output_dir: true

# 梯度检查点（Gradient Checkpointing）
# 原理：正常训练时需要保存每一层的中间结果用于反向传播，很占显存
# 开启梯度检查点后，只保存部分中间结果，需要时重新计算
# 代价：训练速度慢约 20-30%
# 收益：显存占用大幅减少（对 12GB 显存的笔记本很重要！）
gradient_checkpointing: true
