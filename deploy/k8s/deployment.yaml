# ============================================================================
# deployment.yaml — Kubernetes Deployment 配置
# ============================================================================
#
# 什么是 Deployment？
# Deployment 是 Kubernetes 中管理「无状态应用」的资源。
# 它负责：
# 1. 创建指定数量的 Pod（容器组）
# 2. 监控 Pod 的健康状态
# 3. 自动重启失败的 Pod
# 4. 支持滚动更新（不停机更新应用）
#
# 核心概念：
#   Deployment → 管理 ReplicaSet → 管理 Pod → 运行 Container
#
# 使用方法：
#   kubectl apply -f deploy/k8s/deployment.yaml    # 创建/更新
#   kubectl get pods                               # 查看 Pod 状态
#   kubectl logs -f <pod-name>                     # 查看日志
#   kubectl delete -f deploy/k8s/deployment.yaml   # 删除
# ============================================================================

# apiVersion 和 kind 定义了这是什么类型的 K8s 资源
apiVersion: apps/v1      # apps/v1 是 Deployment 的 API 版本
kind: Deployment          # 资源类型：Deployment

# ---- 元数据 ----
metadata:
  name: qwen3-fc-inference        # Deployment 的名称
  namespace: default               # 命名空间（default 是默认的）
  labels:                          # 标签：用于选择和筛选资源
    app: qwen3-fc                  # 应用名称
    component: inference           # 组件类型
    version: v1                    # 版本

# ---- 规格定义 ----
spec:
  # 副本数：运行几个 Pod
  replicas: 1

  # 选择器：Deployment 通过标签选择它管理的 Pod
  # 这里的标签必须与 template.metadata.labels 匹配
  selector:
    matchLabels:
      app: qwen3-fc
      component: inference

  # 更新策略
  strategy:
    type: RollingUpdate        # 滚动更新（逐步替换旧 Pod）
    rollingUpdate:
      maxSurge: 1              # 更新时最多多出 1 个 Pod
      maxUnavailable: 0        # 更新时不允许有不可用的 Pod（保证服务不中断）

  # ---- Pod 模板 ----
  # template 定义了每个 Pod 的详细配置
  template:
    metadata:
      labels:
        app: qwen3-fc
        component: inference
      annotations:
        # Prometheus 注解：让 Prometheus 自动发现并抓取这个 Pod 的指标
        prometheus.io/scrape: "true"     # 启用抓取
        prometheus.io/port: "8000"       # 指标端口
        prometheus.io/path: "/metrics"   # 指标路径

    spec:
      # GPU 运行时类：需要集群安装了 NVIDIA GPU Operator
      runtimeClassName: nvidia

      # 容忍度：允许 Pod 调度到有 GPU 污点的节点
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

      # ---- 容器定义 ----
      containers:
        - name: vllm-server
          image: qwen3-fc-inference:latest
          imagePullPolicy: IfNotPresent

          # 端口
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP

          # 环境变量
          env:
            - name: GPU_MEMORY_UTILIZATION
              value: "0.90"
            - name: MAX_MODEL_LEN
              value: "4096"
            # 从 Pod 元数据获取信息（用于日志标识）
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace

          # 启动命令
          command: ["python", "-m", "vllm.entrypoints.openai.api_server"]
          args:
            - "--model"
            - "/app/model"
            - "--port"
            - "8000"
            - "--host"
            - "0.0.0.0"
            - "--gpu-memory-utilization"
            - "0.90"
            - "--max-model-len"
            - "4096"
            - "--trust-remote-code"
            - "--dtype"
            - "bfloat16"
            - "--enforce-eager"

          # ---- 资源限制 ----
          resources:
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4"
              memory: "12Gi"
              nvidia.com/gpu: "1"

          # ---- 健康检查 ----
          # livenessProbe: 存活检查
          # 检查容器是否还活着，失败则重启
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 120    # 模型加载需要时间
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3

          # readinessProbe: 就绪检查
          # 检查容器是否准备好接收请求
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 3

          # startupProbe: 启动检查
          # 在容器启动阶段使用，防止慢启动的容器被 liveness 杀掉
          startupProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 30   # 最多等 30 × 10 = 300 秒（5分钟）

      # 优雅终止时间：Pod 被删除时，最多等多少秒让它处理完当前请求
      terminationGracePeriodSeconds: 60
