# ğŸ› ï¸ Qwen3-0.6B Function Calling å¾®è°ƒé¡¹ç›®

> **ä¸€å¥è¯æ¦‚æ‹¬**ï¼šå°† Qwen3-0.6B åŸºåº§æ¨¡å‹é€šè¿‡ SFT + GRPO å¼ºåŒ–å­¦ä¹ å¾®è°ƒä¸ºé«˜è´¨é‡ AI Agent å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰åŠ©æ‰‹ï¼Œå¹¶éƒ¨ç½²åˆ° vLLM ç”Ÿäº§ç¯å¢ƒã€‚
>
> **One-liner**: Fine-tune Qwen3-0.6B into a production-grade AI Agent Function Calling assistant via SFT + GRPO reinforcement learning, with full vLLM deployment pipeline.

---

## ğŸ“– ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [ä¸‰æ¡å‘½ä»¤å¤ç°](#ä¸‰æ¡å‘½ä»¤å¤ç°)
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [éƒ¨ç½²æœåŠ¡](#éƒ¨ç½²æœåŠ¡)
- [GRPO å¼ºåŒ–å­¦ä¹ ](#grpo-å¼ºåŒ–å­¦ä¹ å¿…é¡»)
- [é¢è¯•å‡†å¤‡æ–‡æ¡£](#é¢è¯•å‡†å¤‡æ–‡æ¡£)

---

## é¡¹ç›®ç®€ä»‹

### ä»€ä¹ˆæ˜¯ Function Callingï¼Ÿ

Function Callingï¼ˆå‡½æ•°è°ƒç”¨ï¼‰æ˜¯è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å­¦ä¼š"è°ƒç”¨å·¥å…·"çš„èƒ½åŠ›ã€‚å½“ç”¨æˆ·æé—®æ—¶ï¼Œæ¨¡å‹ä¸æ˜¯ç›´æ¥å›ç­”ï¼Œè€Œæ˜¯è¾“å‡ºä¸€ä¸ªç»“æ„åŒ–çš„ JSONã€‚

**ç¤ºä¾‹**ï¼š
```
ç”¨æˆ·ï¼šåŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
æ¨¡å‹è¾“å‡ºï¼š{"name": "get_weather", "arguments": {"city": "åŒ—äº¬", "unit": "celsius"}}
```

### ä¸ºä»€ä¹ˆé€‰æ‹© Qwen3-0.6Bï¼Ÿ

- å°å·§é«˜æ•ˆï¼š0.6B å‚æ•°é‡ï¼Œå•å¡å³å¯è®­ç»ƒ
- æ ¼å¼å­¦ä¹ å¿«ï¼šå°æ¨¡å‹+ä¸¥æ ¼æ ¼å¼=å¿«é€Ÿæ”¶æ•›
- ç«¯ä¾§å¯ç”¨ï¼šé‡åŒ–åå¯åœ¨æ‰‹æœº/ç¬”è®°æœ¬ç¦»çº¿è¿è¡Œ

### æŠ€æœ¯æ ˆ

```
è®­ç»ƒæ¡†æ¶ï¼šLLaMA-Factory
è®­ç»ƒæ•°æ®ï¼šSalesforce/xlam-function-calling-60kï¼ˆ60K æ ·æœ¬ï¼‰
æ¨ç†å¼•æ“ï¼švLLMï¼ˆPagedAttentionï¼‰
éƒ¨ç½²å¹³å°ï¼šDocker + Kubernetes + Helm
ç¡¬ä»¶è¦æ±‚ï¼šNVIDIA GPUï¼ˆâ‰¥12GB æ˜¾å­˜ï¼‰
```

---

## ğŸš€ ä¸‰æ¡å‘½ä»¤å¤ç°

```bash
# 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
bash scripts/setup_env.sh

# 2ï¸âƒ£ è®­ç»ƒï¼ˆSFT â†’ LoRAåˆå¹¶ â†’ GRPO å…¨æµç¨‹ï¼‰
bash scripts/train.sh

# 3ï¸âƒ£ å¯åŠ¨æœåŠ¡
bash scripts/serve.sh --model outputs/qwen3-0.6b-fc-merged
```

---

## ç¯å¢ƒå‡†å¤‡

### ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ |
|------|---------|
| GPU | â‰¥12GB æ˜¾å­˜ï¼ˆRTX 4070/3060/4090ï¼‰|
| å†…å­˜ | 16 GB |
| ç¡¬ç›˜ | 20 GB |

### ä¸€é”®ç¯å¢ƒæ­å»º

```bash
bash scripts/setup_env.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. åˆ›å»º conda ç¯å¢ƒ `qwen-fc`
2. å®‰è£… PyTorchï¼ˆCUDAï¼‰
3. å®‰è£… LLaMA-Factory
4. å®‰è£… vLLM
5. æ£€æµ‹ GPU

### æ‰‹åŠ¨å®‰è£…

```bash
conda create -n qwen-fc python=3.10 -y
conda activate qwen-fc
pip install -r requirements.txt
pip install llamafactory[torch,metrics]
pip install vllm

# éªŒè¯ GPU
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

---

## æ•°æ®å‡†å¤‡

### æ•°æ®é›†

ä½¿ç”¨ [Salesforce/xlam-function-calling-60k](https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k)ï¼ˆéœ€ç™»å½• HuggingFace æ¥å—æ¡æ¬¾ï¼‰

### è¿è¡Œæ•°æ®å‡†å¤‡

```bash
conda activate qwen-fc
python scripts/prepare_data.py
```

**è¾“å‡º**ï¼š
```
data/processed/
â”œâ”€â”€ train.jsonï¼ˆçº¦ 54,000 æ¡ï¼‰
â””â”€â”€ val.jsonï¼ˆçº¦ 6,000 æ¡ï¼‰
```

---

## æ¨¡å‹è®­ç»ƒ

### å¼€å§‹è®­ç»ƒ

```bash
conda activate qwen-fc
bash scripts/train.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨æ‰§è¡Œï¼š
1. **SFT**ï¼šLoRA å¾®è°ƒï¼ˆ~4-6 å°æ—¶ï¼‰
2. **åˆå¹¶**ï¼šLoRA â†’ åŸºåº§æ¨¡å‹
3. **GRPO**ï¼šå¼ºåŒ–å­¦ä¹ å¯¹é½ï¼ˆ~2-4 å°æ—¶ï¼‰

### è®­ç»ƒé…ç½®

| å‚æ•° | å€¼ |
|------|-----|
| æ¨¡å‹ | Qwen/Qwen3-0.6B |
| LoRA rank | 32 |
| batch_size | 2 |
| learning_rate | 2e-4 |
| epochs | 3 |

### è®­ç»ƒè¾“å‡º

```
outputs/qwen3-0.6b-fc-lora/      # LoRA é€‚é…å™¨
outputs/qwen3-0.6b-fc-merged/    # åˆå¹¶åçš„æ¨¡å‹
outputs/qwen3-0.6b-fc-grpo/      # GRPO åçš„æ¨¡å‹
```

---

## æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°åˆå¹¶åçš„æ¨¡å‹
python eval/evaluate.py \
    --model_path outputs/qwen3-0.6b-fc-merged \
    --test_data data/processed/val.json \
    --output_dir eval/
```

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | ç›®æ ‡ |
|------|------|------|
| Parse Rate | JSON è§£ææˆåŠŸç‡ | 95%+ |
| Schema Hit | æ»¡è¶³ schema çº¦æŸ | 88%+ |
| Func Accuracy | å‡½æ•°åå‡†ç¡®ç‡ | 90%+ |
| Exec Rate | å¯æ‰§è¡Œæ¯”ä¾‹ | 80%+ |

---

## éƒ¨ç½²æœåŠ¡

### æœ¬åœ°æœåŠ¡

```bash
# å¯åŠ¨ vLLM
bash scripts/serve.sh --model outputs/qwen3-0.6b-fc-merged

# æµ‹è¯•
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-0.6b-fc-merged",
    "messages": [{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
  }'
```

### Docker éƒ¨ç½²

```bash
bash scripts/deploy.sh docker
```

æœåŠ¡åœ°å€ï¼š
- vLLM: http://localhost:8000
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin)

---

## GRPO å¼ºåŒ–å­¦ä¹ ï¼ˆå¿…é¡»ï¼‰

GRPO å·²é›†æˆåˆ° `train.sh` ä¸­ï¼Œè‡ªåŠ¨æ‰§è¡Œã€‚

### å¥–åŠ±å‡½æ•°

| å¥–åŠ± | æƒé‡ |
|------|------|
| JSON è§£æ | 0.25 |
| Schema å‘½ä¸­ | 0.25 |
| æ¨¡æ‹Ÿæ‰§è¡Œ | 0.25 |
| è¯­ä¹‰åŒ¹é… | 0.25 |

---

## é¢è¯•å‡†å¤‡æ–‡æ¡£

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| [çŸ¥è¯†ç‚¹å¤§çº²](docs/çŸ¥è¯†ç‚¹å¤§çº².md) | ç³»ç»ŸåŒ–çŸ¥è¯†åœ°å›¾ |
| [é¢è¯•é€ŸæŸ¥å¡](docs/é¢è¯•é€ŸæŸ¥å¡.md) | 5 å¼ é€ŸæŸ¥å¡ |
| [æ·±åº¦è¿½é—®](docs/æ·±åº¦è¿½é—®.md) | æ·±åº¦è¿½é—®åŠç­”æ¡ˆ |
| [ä»£ç èµ°è¯»æŒ‡å—](docs/ä»£ç èµ°è¯»æŒ‡å—.md) | ä»£ç èµ°è¯»è¦ç‚¹ |

---

## è‡´è°¢

- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- [vLLM](https://github.com/vllm-project/vllm)
- [xlam-function-calling-60k](https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k)
- [Qwen3](https://github.com/QwenLM/Qwen3)

---

<p align="center"><i>Built with â¤ï¸</i></p>
