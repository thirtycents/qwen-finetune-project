# 项目开发遇到的核心问题与解决方案 (面试准备)

本文档记录了在 Qwen3-0.6B Function Calling 微调项目开发过程中遇到的实际技术挑战、排查思路及解决方案。可用于面试中展示解决问题的能力。

---

## 1. 硬件适配：RTX 5070 Ti (Blackwell 架构) 兼容性问题

### 🔴 问题描述
在最新的 RTX 5070 Ti 显卡上，使用标准的 PyTorch (Stable) 版本（通常基于 CUDA 11.8 或 12.4）可能无法识别显卡或无法正常调用 CUDA 核心，导致训练无法启动或推理报错。

### 🔍 原因分析
RTX 50 系显卡基于最新的 **Blackwell (sm_120)** 架构。主流的 PyTorch Stable 版本尚未完全集成对该架构的 PTX/SASS 编译支持。旧版 CUDA Toolkit (12.1/12.4) 可能缺乏对新硬件的底层驱动支持。

### ✅ 解决方案
切换至 **PyTorch Nightly (Preview)** 版本，强制指定 **CUDA 12.8**。

```bash
# 卸载旧版
pip uninstall torch torchvision torchaudio

# 安装预览版 (兼容 sm_120)
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```

**面试话术**：
> "在项目初期，我遇到了新发布的 RTX 5070 Ti 显卡驱动兼容性问题。标准版 PyTorch 无法识别设备。通过查阅 NVIDIA 和 PyTorch 社区文档，我定位到是因为新架构（Blackwell）需要更高版本的 CUDA Toolkit 支持。最终我通过迁移到 PyTorch Nightly Build 并配合 CUDA 12.8 解决了底层算力调用问题，确保了项目在最新硬件上的运行。"

---

## 2. 显存优化：12GB 显存下的 OOM (Out Of Memory)

### 🔴 问题描述
尽管模型仅为 0.6B 参数，但在全量微调或 Batch Size 设置不当时，仍会瞬间爆显存（CUDA OOM），报错提示 `Tried to allocate X GiB...`。

### 🔍 原因分析
LLM 训练的显存占用不仅包含模型权重，还包含：
1. **梯度 (Gradients)**：与权重同等大小。
2. **优化器状态 (Optimizer States)**：AdamW 需要维护一阶和二阶动量（权重大小的 2 倍）。
3. **激活值 (Activations)**：随 Batch Size 和序列长度线性/二次方增长。

### ✅ 解决方案 (多管齐下)
1. **降低 Batch Size**：将 `per_device_train_batch_size` 从 4 降至 1。
2. **梯度累积 (Gradient Accumulation)**：通过 `gradient_accumulation_steps=4`，在显存有限的情况下模拟大 Batch Size 的训练效果。
3. **内存碎片优化**：设置环境变量 `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`，减少内存碎片化导致的分配失败。
4. **混合精度/量化**：使用 LoRA (Low-Rank Adaptation) 仅微调部分参数，或启用 QLoRA (4-bit) 进一步压缩基座模型。

**面试话术**：
> "在资源受限的 12GB 显卡上训练时，我遇到了 OOM 挑战。我首先分析了显存占用的构成，发现优化器状态和激活值是主要瓶颈。我采用了'时间换空间'的策略，降低单步 Batch Size 并引入梯度累积（Gradient Accumulation）来保持训练稳定性。同时，通过调整 PyTorch 的内存分配策略（expandable_segments），有效解决了显存碎片化问题，最终在消费级显卡上完成了模型微调。"

---

## 3. 全球化：Streamlit 看板的动态国际化 (i18n)

### 🔴 问题描述
原项目仅支持英文界面，无法满足中文用户的可视化监控需求。Streamlit 框架原生缺乏标准的 i18n 解决方案。

### 🔍 原因分析
Streamlit 是即时渲染模式（Immediate Mode），每次交互都会重跑整个脚本。简单的全局变量切换语言会导致状态重置或不一致。

### ✅ 解决方案
1. **状态管理**：使用 `st.session_state` 持久化存储用户选择的语言 (`current_lang`)。
2. **字典映射**：构建 `TRANSLATIONS` 字典，通过键值对管理中英文文案。
3. **辅助函数**：封装 `t(key)` 函数，根据当前 Session State 动态返回对应语言的字符串。
4. **UI 组件**：在 Sidebar 添加 `st.radio` 或 `st.selectbox` 触发 `rerun`，实现无刷新（视觉上）语言切换。

**面试话术**：
> "为了提升工具的易用性，我为其添加了双语支持。针对 Streamlit 的即时渲染特性，我设计了一套基于 Session State 的轻量级翻译层。通过封装翻译函数和状态钩子，实现了界面语言的实时无缝切换，既满足了国际化需求，又保持了代码的简洁性。"

---

## 4. 自动化运维：Shell 脚本中的 Conda 环境激活

### 🔴 问题描述
编写 `start_dashboard.sh` 等自动化脚本时，直接使用 `conda activate qwen-fc` 经常报错 `CommandNotFoundError` 或环境未实际切换。

### 🔍 原因分析
`conda activate` 依赖于 Shell 的 hook 初始化。在非交互式 Shell 脚本（Non-interactive shell）中，`.bashrc` 往往不会被加载，导致 conda 命令不可用。

### ✅ 解决方案
在脚本显式执行 Conda 的初始化代码：

```bash
# 获取 conda shell hook
eval "$(conda shell.bash hook)"
# 只有初始化后，activate 才能生效
conda activate qwen-fc
```

**面试话术**：
> "在构建自动化部署脚本时，我处理了 Conda 环境在 Shell 脚本中激活失效的问题。深入理解 Shell 启动模式后，我通过显式注入 Conda Hook，确保了脚本在 CI/CD 或后台任务中也能正确切换 Python 环境，提高了工程的健壮性。"
